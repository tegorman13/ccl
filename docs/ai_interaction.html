<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.35">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Thomas E. Gorman">
<meta name="dcterms.date" content="2024-11-18">

<title>Interactive AI Lit – CCL Projects</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-383d4a065b21370043bc4709e21900a7.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7fa2055fb7403aac80cb702c524d448d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="Assets/Style/calloutTG.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ai_gd.html">LLM Literature</a></li><li class="breadcrumb-item"><a href="./ai_interaction.html">Interactive AI Lit</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CCL Projects</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tegorman13/ccl" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">LLM Literature</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_gd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Group Decision Lit</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_decision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Individual decision lit</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./llm_energy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLM Energy Lit Highlights</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_interaction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Interactive AI Lit</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Misc</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transactive Memory Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Samuel_Project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Samuel’s Project</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Driving.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Driving Lit</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#task-supportive-and-personalized-human-large-language-model-interaction-a-user-study." id="toc-task-supportive-and-personalized-human-large-language-model-interaction-a-user-study." class="nav-link active" data-scroll-target="#task-supportive-and-personalized-human-large-language-model-interaction-a-user-study.">Task Supportive and Personalized Human-Large Language Model Interaction: A User Study.</a></li>
  <li><a href="#transitioning-to-human-centered-ai-a-systematic-review-of-theories-scenarios-and-hypotheses-in-human-ai-interactions." id="toc-transitioning-to-human-centered-ai-a-systematic-review-of-theories-scenarios-and-hypotheses-in-human-ai-interactions." class="nav-link" data-scroll-target="#transitioning-to-human-centered-ai-a-systematic-review-of-theories-scenarios-and-hypotheses-in-human-ai-interactions.">Transitioning to Human-Centered AI: A Systematic Review of Theories, Scenarios, and Hypotheses in Human-AI Interactions.</a></li>
  <li><a href="#human-creativity-in-the-age-of-llms-randomized-experiments-on-divergent-and-convergent-thinking" id="toc-human-creativity-in-the-age-of-llms-randomized-experiments-on-divergent-and-convergent-thinking" class="nav-link" data-scroll-target="#human-creativity-in-the-age-of-llms-randomized-experiments-on-divergent-and-convergent-thinking">Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking</a></li>
  <li><a href="#to-trust-or-to-think-cognitive-forcing-functions-can-reduce-overreliance-on-ai-in-ai-assisted-decision-making" id="toc-to-trust-or-to-think-cognitive-forcing-functions-can-reduce-overreliance-on-ai-in-ai-assisted-decision-making" class="nav-link" data-scroll-target="#to-trust-or-to-think-cognitive-forcing-functions-can-reduce-overreliance-on-ai-in-ai-assisted-decision-making">To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making</a></li>
  <li><a href="#ai-can-help-humans-find-common-ground-in-democratic-deliberation." id="toc-ai-can-help-humans-find-common-ground-in-democratic-deliberation." class="nav-link" data-scroll-target="#ai-can-help-humans-find-common-ground-in-democratic-deliberation.">AI can help humans find common ground in democratic deliberation.</a></li>
  <li><a href="#evaluating-language-models-for-mathematics-through-interactions" id="toc-evaluating-language-models-for-mathematics-through-interactions" class="nav-link" data-scroll-target="#evaluating-language-models-for-mathematics-through-interactions">Evaluating Language Models for Mathematics through Interactions</a></li>
  <li><a href="#large-language-models-experimentation-interface" id="toc-large-language-models-experimentation-interface" class="nav-link" data-scroll-target="#large-language-models-experimentation-interface">Large Language Models Experimentation Interface</a></li>
  <li><a href="#human-ai-collaboration-in-cooperative-games-a-study-of-playing-codenames-with-an-llm-assistant" id="toc-human-ai-collaboration-in-cooperative-games-a-study-of-playing-codenames-with-an-llm-assistant" class="nav-link" data-scroll-target="#human-ai-collaboration-in-cooperative-games-a-study-of-playing-codenames-with-an-llm-assistant">Human-AI Collaboration in Cooperative Games: A Study of Playing Codenames with an LLM Assistant</a></li>
  <li><a href="#effects-of-interacting-with-a-large-language-model-compared-with-a-human-coach-on-the-clinical-diagnostic-process-and-outcomes-among-fourth-year-medical-students-study-protocol-for-a-prospective-randomised-experiment-using-patient-vignettes" id="toc-effects-of-interacting-with-a-large-language-model-compared-with-a-human-coach-on-the-clinical-diagnostic-process-and-outcomes-among-fourth-year-medical-students-study-protocol-for-a-prospective-randomised-experiment-using-patient-vignettes" class="nav-link" data-scroll-target="#effects-of-interacting-with-a-large-language-model-compared-with-a-human-coach-on-the-clinical-diagnostic-process-and-outcomes-among-fourth-year-medical-students-study-protocol-for-a-prospective-randomised-experiment-using-patient-vignettes">Effects of interacting with a large language model compared with a human coach on the clinical diagnostic process and outcomes among fourth-year medical students: Study protocol for a prospective, randomised experiment using patient vignettes</a></li>
  <li><a href="#enhancing-ai-assisted-group-decision-making-through-llm-powered-devils-advocate." id="toc-enhancing-ai-assisted-group-decision-making-through-llm-powered-devils-advocate." class="nav-link" data-scroll-target="#enhancing-ai-assisted-group-decision-making-through-llm-powered-devils-advocate.">Enhancing AI-Assisted Group Decision Making through LLM-Powered Devil’s Advocate.</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="ai_interaction.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li><li><a href="ai_interaction.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="interactive_ai_lit_notes.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ai_gd.html">LLM Literature</a></li><li class="breadcrumb-item"><a href="./ai_interaction.html">Interactive AI Lit</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Interactive AI Lit</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://tegorman13.github.io/">Thomas E. Gorman</a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://web.ics.purdue.edu/~treimer/">
            Communication and Cognition Lab, Purdue University, USA
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 18, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="task-supportive-and-personalized-human-large-language-model-interaction-a-user-study." class="level2">
<h2 class="anchored" data-anchor-id="task-supportive-and-personalized-human-large-language-model-interaction-a-user-study.">Task Supportive and Personalized Human-Large Language Model Interaction: A User Study.</h2>
<p>Wang, B., Liu, J., Karimnazarov, J., &amp; Thompson, N. (2024). Task Supportive and Personalized Human-Large Language Model Interaction: A User Study. Proceedings of the 2024 ACM SIGIR Conference on Human Information Interaction and Retrieval, 370–375. https://doi.org/10.1145/3627508.3638344</p>
<details class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>Large language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.</p>
</div>
</details>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/Wang_Liu1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure from @wangTaskSupportivePersonalized2024"><img src="images/Wang_Liu1.png" class="img-fluid figure-img" alt="Figure from B. Wang et al. (2024)"></a></p>
<figcaption>Figure from <span class="citation" data-cites="wangTaskSupportivePersonalized2024">B. Wang et al. (<a href="#ref-wangTaskSupportivePersonalized2024" role="doc-biblioref">2024</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="transitioning-to-human-centered-ai-a-systematic-review-of-theories-scenarios-and-hypotheses-in-human-ai-interactions." class="level2">
<h2 class="anchored" data-anchor-id="transitioning-to-human-centered-ai-a-systematic-review-of-theories-scenarios-and-hypotheses-in-human-ai-interactions.">Transitioning to Human-Centered AI: A Systematic Review of Theories, Scenarios, and Hypotheses in Human-AI Interactions.</h2>
<p>Wang, D., Zheng, K., Li, C., &amp; Guo, J. (2024). <strong>Transitioning to Human-Centered AI: A Systematic Review of Theories, Scenarios, and Hypotheses in Human-AI Interactions.</strong> Proceedings of the Association for Information Science and Technology, 61(1), 673–678. https://doi.org/10.1002/pra2.1078</p>
<details class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>This study conducted a systematic review of human-AI interaction (HAI)over the past decade for the implemented theories and scenarios, and the tested hypotheses to discover the changes in the current transition to human-centered AI (HCAI). Moving from acceptance theories, Computers are social actors (CASA), anthropomorphism, and the integrative trust model are the most frequent theories. Augmentation scenarios of decision-making, teamwork, and human-AI collaborations are common in the latest HAI studies. Users’ trust, acceptance, and intention to use an AI system are the main research targets in HAI studies. These trends show a clear transition toward HCAI. This paper also discusses opportunities tied to HAI studies based on the interconnections between the various theories, scenarios, and hypotheses.</p>
</div>
</details>
<div id="fig-wang" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wang-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><a href="images/Wang1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;1: Figures from @wangTransitioningHumanCenteredAI2024"><img src="images/Wang1.png" class="img-fluid figure-img"></a></p>
<p><a href="images/Wang2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;1: Figures from @wangTransitioningHumanCenteredAI2024"><img src="images/Wang2.png" class="img-fluid figure-img"></a></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wang-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Figures from <span class="citation" data-cites="wangTransitioningHumanCenteredAI2024">D. Wang et al. (<a href="#ref-wangTransitioningHumanCenteredAI2024" role="doc-biblioref">2024</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="human-creativity-in-the-age-of-llms-randomized-experiments-on-divergent-and-convergent-thinking" class="level2">
<h2 class="anchored" data-anchor-id="human-creativity-in-the-age-of-llms-randomized-experiments-on-divergent-and-convergent-thinking">Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking</h2>
<p>Kumar, H., Vincentius, J., Jordan, E., &amp; Anderson, A. (2024). <strong>Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking</strong> (No.&nbsp;arXiv:2410.03703). arXiv. http://arxiv.org/abs/2410.03703</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>Large language models are transforming the creative process by offering unprecedented capabilities to algorithmically generate ideas. While these tools can enhance human creativity when people co-create with them, it’s unclear how this will impact unassisted human creativity. We conducted two large pre-registered parallel experiments involving 1,100 participants attempting tasks targeting the two core components of creativity, divergent and convergent thinking. We compare the effects of two forms of large language model (LLM) assistance – a standard LLM providing direct answers and a coach-like LLM offering guidance – with a control group receiving no AI assistance, and focus particularly on how all groups perform in a final, unassisted stage. Our findings reveal that while LLM assistance can provide short-term boosts in creativity during assisted tasks, it may inadvertently hinder independent creative performance when users work without assistance, raising concerns about the long-term impact on human creativity and cognition.</p>
</div>
</details>
<div id="fig-kumar" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kumar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><a href="images/Kumar1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;2: Figures from @kumarHumanCreativityAge2024"><img src="images/Kumar1.png" class="img-fluid figure-img"></a></p>
<p><a href="images/Kumar2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;2: Figures from @kumarHumanCreativityAge2024"><img src="images/Kumar2.png" class="img-fluid figure-img"></a></p>
<p><a href="images/Kumar3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;2: Figures from @kumarHumanCreativityAge2024"><img src="images/Kumar3.png" class="img-fluid figure-img"></a></p>
<p><a href="images/Kumar4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;2: Figures from @kumarHumanCreativityAge2024"><img src="images/Kumar4.png" class="img-fluid figure-img"></a></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kumar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Figures from <span class="citation" data-cites="kumarHumanCreativityAge2024">Kumar et al. (<a href="#ref-kumarHumanCreativityAge2024" role="doc-biblioref">2024</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="to-trust-or-to-think-cognitive-forcing-functions-can-reduce-overreliance-on-ai-in-ai-assisted-decision-making" class="level2">
<h2 class="anchored" data-anchor-id="to-trust-or-to-think-cognitive-forcing-functions-can-reduce-overreliance-on-ai-in-ai-assisted-decision-making">To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making</h2>
<p>Buçinca, Z., Malaya, M. B., &amp; Gajos, K. Z. (2021). <strong>To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making.</strong> Proceedings of the ACM on Human-Computer Interaction, 5(CSCW1), 1–21. https://doi.org/10.1145/3449287</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>People supported by AI-powered decision support tools frequently overrely on the AI: they accept an AI’s suggestion even when that suggestion is wrong. Adding explanations to the AI decisions does not appear to reduce the overreliance and some studies suggest that it might even increase it. Informed by the dual-process theory of cognition, we posit that people rarely engage analytically with each individual AI recommendation and explanation, and instead develop general heuristics about whether and when to follow the AI suggestions. Building on prior research on medical decision-making, we designed three cognitive forcing interventions to compel people to engage more thoughtfully with the AI-generated explanations. We conducted an experiment (N=199), in which we compared our three cognitive forcing designs to two simple explainable AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing significantly reduced overreliance compared to the simple explainable AI approaches. However, there was a trade-off: people assigned the least favorable subjective ratings to the designs that reduced the overreliance the most. To audit our work for intervention-generated inequalities, we investigated whether our interventions benefited equally people with different levels of Need for Cognition (i.e., motivation to engage in effortful mental activities). Our results show that, on average, cognitive forcing interventions benefited participants higher in Need for Cognition more. Our research suggests that human cognitive motivation moderates the effectiveness of explainable AI solutions.</p>
</div>
</details>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/Bucina1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure from @bucincaTrustThinkCognitive2021"><img src="images/Bucina1.png" class="img-fluid figure-img" alt="Figure from Buçinca et al. (2021)"></a></p>
<figcaption>Figure from <span class="citation" data-cites="bucincaTrustThinkCognitive2021">Buçinca et al. (<a href="#ref-bucincaTrustThinkCognitive2021" role="doc-biblioref">2021</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="ai-can-help-humans-find-common-ground-in-democratic-deliberation." class="level2">
<h2 class="anchored" data-anchor-id="ai-can-help-humans-find-common-ground-in-democratic-deliberation.">AI can help humans find common ground in democratic deliberation.</h2>
<p>Tessler, M. H., Bakker, M. A., Jarrett, D., Sheahan, H., Chadwick, M. J., Koster, R., Evans, G., Campbell-Gillingham, L., Collins, T., Parkes, D. C., Botvinick, M., &amp; Summerfield, C. (2024). <strong>AI can help humans find common ground in democratic deliberation.</strong> Science, 386(6719), eadq2852. https://doi.org/10.1126/science.adq2852</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>Finding agreement through a free exchange of views is often difficult. Collective deliberation can be slow, difficult to scale, and unequally attentive to different voices. In this study, we trained an artificial intelligence (AI) to mediate human deliberation. Using participants’ personal opinions and critiques, the AI mediator iteratively generates and refines statements that express common ground among the group on social or political issues. Participants (N = 5734) preferred AI-generated statements to those written by human mediators, rating them as more informative, clear, and unbiased. Discussants often updated their views after the deliberation, converging on a shared perspective. Text embeddings revealed that successful group statements incorporated dissenting voices while respecting the majority position. These findings were replicated in a virtual citizens’ assembly involving a demographically representative sample of the UK population.</p>
</div>
</details>
<div id="fig-tessler" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tessler-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><a href="images/tessler1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;3: Figures from @tesslerAICanHelp2024"><img src="images/tessler1.png" class="img-fluid figure-img"></a></p>
<p><a href="images/tessler2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;3: Figures from @tesslerAICanHelp2024"><img src="images/tessler2.png" class="img-fluid figure-img"></a></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tessler-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Figures from <span class="citation" data-cites="tesslerAICanHelp2024">Tessler et al. (<a href="#ref-tesslerAICanHelp2024" role="doc-biblioref">2024</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="evaluating-language-models-for-mathematics-through-interactions" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-language-models-for-mathematics-through-interactions">Evaluating Language Models for Mathematics through Interactions</h2>
<p>Collins, K. M., Jiang, A. Q., Frieder, S., Wong, L., Zilka, M., Bhatt, U., Lukasiewicz, T., Wu, Y., Tenenbaum, J. B., Hart, W., Gowers, T., Li, W., Weller, A., &amp; Jamnik, M. (2023). <strong>Evaluating Language Models for Mathematics through Interactions</strong> (No.&nbsp;arXiv:2306.01694). arXiv. http://arxiv.org/abs/2306.01694</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>The standard methodology of evaluating large language models (LLMs) based on static pairs of inputs and outputs is insufficient for developing assistants: this kind of assessments fails to take into account the essential interactive element in their deployment, and therefore limits how we understand language model capabilities. We introduce CheckMate, an adaptable prototype platform for humans to interact with and evaluate LLMs. We conduct a study with CheckMate to evaluate three language models~(InstructGPT, ChatGPT, and GPT-4) as assistants in proving undergraduate-level mathematics, with a mixed cohort of participants from undergraduate students to professors of mathematics. We release the resulting interaction and rating dataset, MathConverse. By analysing MathConverse, we derive a preliminary taxonomy of human behaviours and uncover that despite a generally positive correlation, there are notable instances of divergence between correctness and perceived helpfulness in LLM generations, amongst other findings. Further, we identify useful scenarios and existing issues of GPT-4 in mathematical reasoning through a series of case studies contributed by expert mathematicians. We conclude with actionable takeaways for ML practitioners and mathematicians: models which communicate uncertainty, respond well to user corrections, are more interpretable and concise may constitute better assistants; interactive evaluation is a promising way to continually navigate the capability of these models; humans should be aware of language models’ algebraic fallibility, and for that reason discern where they should be used.</p>
</div>
</details>
<div id="fig-collins_math" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-collins_math-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><a href="images/collins_math1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;4: Figures from @collinsEvaluatingLanguageModels2023"><img src="images/collins_math1.png" class="img-fluid figure-img"></a></p>
<p><a href="images/collins_math2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;4: Figures from @collinsEvaluatingLanguageModels2023"><img src="images/collins_math2.png" class="img-fluid figure-img"></a></p>
<p><a href="images/collins_math3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure&nbsp;4: Figures from @collinsEvaluatingLanguageModels2023"><img src="images/collins_math3.png" class="img-fluid figure-img"></a></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-collins_math-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Figures from <span class="citation" data-cites="collinsEvaluatingLanguageModels2023">Collins et al. (<a href="#ref-collinsEvaluatingLanguageModels2023" role="doc-biblioref">2023</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="large-language-models-experimentation-interface" class="level2">
<h2 class="anchored" data-anchor-id="large-language-models-experimentation-interface">Large Language Models Experimentation Interface</h2>
<p>Laban, G., Laban, T., &amp; Gunes, H. (2024). <strong>LEXI: Large Language Models Experimentation Interface</strong> (No.&nbsp;arXiv:2407.01488). arXiv. http://arxiv.org/abs/2407.01488</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>The recent developments in Large Language Models (LLM), mark a significant moment in the research and development of social interactions with artificial agents. These agents are widely deployed in a variety of settings, with potential impact on users. However, the study of social interactions with agents powered by LLM is still emerging, limited by access to the technology and to data, the absence of standardised interfaces, and challenges to establishing controlled experimental setups using the currently available business-oriented platforms. To answer these gaps, we developed LEXI, LLMs Experimentation Interface, an open-source tool enabling the deployment of artificial agents powered by LLM in social interaction behavioural experiments. Using a graphical interface, LEXI allows researchers to build agents, and deploy them in experimental setups along with forms and questionnaires while collecting interaction logs and self-reported data. The outcomes of usability testing indicate LEXI’s broad utility, high usability and minimum mental workload requirement, with distinctive benefits observed across disciplines. A proof-of-concept study exploring the tool’s efficacy in evaluating social HAIs was conducted, resulting in high-quality data. A comparison of empathetic versus neutral agents indicated that people perceive empathetic agents as more social, and write longer and more positive messages towards them.</p>
</div>
</details>
<p><span class="citation" data-cites="labanLEXILargeLanguage2024">Laban et al. (<a href="#ref-labanLEXILargeLanguage2024" role="doc-biblioref">2024</a>)</span></p>
</section>
<section id="human-ai-collaboration-in-cooperative-games-a-study-of-playing-codenames-with-an-llm-assistant" class="level2">
<h2 class="anchored" data-anchor-id="human-ai-collaboration-in-cooperative-games-a-study-of-playing-codenames-with-an-llm-assistant">Human-AI Collaboration in Cooperative Games: A Study of Playing Codenames with an LLM Assistant</h2>
<p>Sidji, M., Smith, W., &amp; Rogerson, M. J. (2024). <strong>Human-AI Collaboration in Cooperative Games: A Study of Playing Codenames with an LLM Assistant.</strong> Proc. ACM Hum.-Comput. Interact., 8(CHI PLAY), 316:1-316:25. https://doi.org/10.1145/3677081</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>Playing partial information, restricted communication, cooperative (PIRCC) games with humans have proven challenging for AI, due to our reliance on social dynamics and sophisticated cognitive techniques. Yet, recent advances in generative AI may change this situation through new forms of human-AI collaboration. This paper investigates how teams of players interact with an AI assistant in the PIRCC game Codenames and the impact this has on cognition, social dynamics, and player experience. We observed gameplay and conducted post-game focus groups with 54 participants across ten groups. Each group played three rounds of Codenames, with an AI assistant supporting Cluegivers. We found the AI assistant enhanced players’ convergent and divergent thinking, but interfered with formation of team mental models, highlighting a tension in the use of AI in creative team scenarios. The presence of the AI challenged many players’ understanding of the ‘spirit of the game’. Furthermore, the presence of the AI assistants weakened social connections between human teammates, but strengthened connections across teams. This paper provides an empirical account of an AI assistant’s effect on cognition, social dynamics, and player experience in Codenames. We highlight the opportunities and challenges that arise when designing hybrid digital boardgames that include AI assistants.</p>
</div>
</details>
<p><span class="citation" data-cites="sidjiHumanAICollaborationCooperative2024">Sidji et al. (<a href="#ref-sidjiHumanAICollaborationCooperative2024" role="doc-biblioref">2024</a>)</span></p>
</section>
<section id="effects-of-interacting-with-a-large-language-model-compared-with-a-human-coach-on-the-clinical-diagnostic-process-and-outcomes-among-fourth-year-medical-students-study-protocol-for-a-prospective-randomised-experiment-using-patient-vignettes" class="level2">
<h2 class="anchored" data-anchor-id="effects-of-interacting-with-a-large-language-model-compared-with-a-human-coach-on-the-clinical-diagnostic-process-and-outcomes-among-fourth-year-medical-students-study-protocol-for-a-prospective-randomised-experiment-using-patient-vignettes">Effects of interacting with a large language model compared with a human coach on the clinical diagnostic process and outcomes among fourth-year medical students: Study protocol for a prospective, randomised experiment using patient vignettes</h2>
<p>Kämmer, J. E., Hautz, W. E., Krummrey, G., Sauter, T. C., Penders, D., Birrenbach, T., &amp; Bienefeld, N. (2024). <strong>Effects of interacting with a large language model compared with a human coach on the clinical diagnostic process and outcomes among fourth-year medical students: Study protocol for a prospective, randomised experiment using patient vignettes.</strong> BMJ Open, 14(7), e087469. https://doi.org/10.1136/bmjopen-2024-087469</p>
<details open="" class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>Versatile large language models (LLMs) have the potential to augment diagnostic decision-­making by assisting diagnosticians, thanks to their ability to engage in open-­ended, natural conversations and their comprehensive knowledge access. Yet the novelty of LLMs in diagnostic decision-­making introduces uncertainties regarding their impact. Clinicians unfamiliar with the use of LLMs in their professional context may rely on general attitudes towards LLMs more broadly, potentially hindering thoughtful use and critical evaluation of their input, leading to either over-­reliance and lack of critical thinking or an unwillingness to use LLMs as diagnostic aids. To address these concerns, this study examines the influence on the diagnostic process and outcomes of interacting with an LLM compared with a human coach, and of prior training vs no training for interacting with either of these ‘coaches’. Our findings aim to illuminate the potential benefits and risks of employing artificial intelligence (AI) in diagnostic decision-­making. Methods and analysis  We are conducting a prospective, randomised experiment with N=158 fourth-­year medical students from Charité Medical School, Berlin, Germany. Participants are asked to diagnose patient vignettes after being assigned to either a human coach or ChatGPT and after either training or no training (both between-­subject factors). We are specifically collecting data on the effects of using either of these ‘coaches’ and of additional training on information search, number of hypotheses entertained, diagnostic accuracy and confidence. Statistical methods will include linear mixed effects models. Exploratory analyses of the interaction patterns and attitudes towards AI will also generate more generalisable knowledge about the role of AI in medicine.</p>
</div>
</details>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/Kammer1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure from @kammerEffectsInteractingLarge2024"><img src="images/Kammer1.png" class="img-fluid figure-img" alt="Figure from Kämmer et al. (2024)"></a></p>
<figcaption>Figure from <span class="citation" data-cites="kammerEffectsInteractingLarge2024">Kämmer et al. (<a href="#ref-kammerEffectsInteractingLarge2024" role="doc-biblioref">2024</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="enhancing-ai-assisted-group-decision-making-through-llm-powered-devils-advocate." class="level2">
<h2 class="anchored" data-anchor-id="enhancing-ai-assisted-group-decision-making-through-llm-powered-devils-advocate.">Enhancing AI-Assisted Group Decision Making through LLM-Powered Devil’s Advocate.</h2>
<p>Chiang, C.-W., Lu, Z., Li, Z., &amp; Yin, M. (2024). <strong>Enhancing AI-Assisted Group Decision Making through LLM-Powered Devil’s Advocate.</strong> Proceedings of the 29th International Conference on Intelligent User Interfaces, 103–119. https://doi.org/10.1145/3640543.3645199</p>
<details class="relevant-callout">
<summary>
Abstract
</summary>
<div>
<p>Group decision making plays a crucial role in our complex and interconnected world. The rise of AI technologies has the potential to provide data-driven insights to facilitate group decision making, although it is found that groups do not always utilize AI assistance appropriately. In this paper, we aim to examine whether and how the introduction of a devil’s advocate in the AI-assisted group deci- sion making processes could help groups better utilize AI assistance and change the perceptions of group processes during decision making. Inspired by the exceptional conversational capabilities ex- hibited by modern large language models (LLMs), we design four different styles of devil’s advocate powered by LLMs, varying their interactivity (i.e., interactive vs.&nbsp;non-interactive) and their target of objection (i.e., challenge the AI recommendation or the majority opinion within the group). Through a randomized human-subject experiment, we find evidence suggesting that LLM-powered devil’s advocates that argue against the AI model’s decision recommenda- tion have the potential to promote groups’ appropriate reliance on AI. Meanwhile, the introduction of LLM-powered devil’s advocate usually does not lead to substantial increases in people’s perceived workload for completing the group decision making tasks, while interactive LLM-powered devil’s advocates are perceived as more collaborating and of higher quality. We conclude by discussing the practical implications of our findings.</p>
</div>
</details>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/chiang_24_img.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Figure from @chiangEnhancingAIAssistedGroup2024"><img src="images/chiang_24_img.png" class="img-fluid figure-img" alt="Figure from Chiang et al. (2024)"></a></p>
<figcaption>Figure from <span class="citation" data-cites="chiangEnhancingAIAssistedGroup2024">Chiang et al. (<a href="#ref-chiangEnhancingAIAssistedGroup2024" role="doc-biblioref">2024</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-bucincaTrustThinkCognitive2021" class="csl-entry" role="listitem">
Buçinca, Z., Malaya, M. B., &amp; Gajos, K. Z. (2021). To <span>Trust</span> or to <span>Think</span>: <span>Cognitive Forcing Functions Can Reduce Overreliance</span> on <span>AI</span> in <span class="nocase">AI-assisted Decision-making</span>. <em>Proceedings of the ACM on Human-Computer Interaction</em>, <em>5</em>(CSCW1), 1–21. <a href="https://doi.org/10.1145/3449287">https://doi.org/10.1145/3449287</a>
</div>
<div id="ref-chiangEnhancingAIAssistedGroup2024" class="csl-entry" role="listitem">
Chiang, C.-W., Lu, Z., Li, Z., &amp; Yin, M. (2024). Enhancing <span>AI-Assisted Group Decision Making</span> through <span>LLM-Powered Devil</span>’s <span>Advocate</span>. <em>Proceedings of the 29th <span>International Conference</span> on <span>Intelligent User Interfaces</span></em>, 103–119. <a href="https://doi.org/10.1145/3640543.3645199">https://doi.org/10.1145/3640543.3645199</a>
</div>
<div id="ref-collinsEvaluatingLanguageModels2023" class="csl-entry" role="listitem">
Collins, K. M., Jiang, A. Q., Frieder, S., Wong, L., Zilka, M., Bhatt, U., Lukasiewicz, T., Wu, Y., Tenenbaum, J. B., Hart, W., Gowers, T., Li, W., Weller, A., &amp; Jamnik, M. (2023). <em>Evaluating <span>Language Models</span> for <span>Mathematics</span> through <span>Interactions</span></em> (arXiv:2306.01694). arXiv. <a href="https://arxiv.org/abs/2306.01694">https://arxiv.org/abs/2306.01694</a>
</div>
<div id="ref-kammerEffectsInteractingLarge2024" class="csl-entry" role="listitem">
Kämmer, J. E., Hautz, W. E., Krummrey, G., Sauter, T. C., Penders, D., Birrenbach, T., &amp; Bienefeld, N. (2024). Effects of interacting with a large language model compared with a human coach on the clinical diagnostic process and outcomes among fourth-year medical students: Study protocol for a prospective, randomised experiment using patient vignettes. <em>BMJ Open</em>, <em>14</em>(7), e087469. <a href="https://doi.org/10.1136/bmjopen-2024-087469">https://doi.org/10.1136/bmjopen-2024-087469</a>
</div>
<div id="ref-kumarHumanCreativityAge2024" class="csl-entry" role="listitem">
Kumar, H., Vincentius, J., Jordan, E., &amp; Anderson, A. (2024). <em>Human <span>Creativity</span> in the <span>Age</span> of <span>LLMs</span>: <span>Randomized Experiments</span> on <span>Divergent</span> and <span>Convergent Thinking</span></em> (arXiv:2410.03703). arXiv. <a href="https://arxiv.org/abs/2410.03703">https://arxiv.org/abs/2410.03703</a>
</div>
<div id="ref-labanLEXILargeLanguage2024" class="csl-entry" role="listitem">
Laban, G., Laban, T., &amp; Gunes, H. (2024). <em><span>LEXI</span>: <span>Large Language Models Experimentation Interface</span></em> (arXiv:2407.01488). arXiv. <a href="https://arxiv.org/abs/2407.01488">https://arxiv.org/abs/2407.01488</a>
</div>
<div id="ref-sidjiHumanAICollaborationCooperative2024" class="csl-entry" role="listitem">
Sidji, M., Smith, W., &amp; Rogerson, M. J. (2024). Human-<span>AI Collaboration</span> in <span>Cooperative Games</span>: <span>A Study</span> of <span>Playing Codenames</span> with an <span>LLM Assistant</span>. <em>Proc. ACM Hum.-Comput. Interact.</em>, <em>8</em>(CHI PLAY), 316:1–316:25. <a href="https://doi.org/10.1145/3677081">https://doi.org/10.1145/3677081</a>
</div>
<div id="ref-tesslerAICanHelp2024" class="csl-entry" role="listitem">
Tessler, M. H., Bakker, M. A., Jarrett, D., Sheahan, H., Chadwick, M. J., Koster, R., Evans, G., Campbell-Gillingham, L., Collins, T., Parkes, D. C., Botvinick, M., &amp; Summerfield, C. (2024). <span>AI</span> can help humans find common ground in democratic deliberation. <em>Science</em>, <em>386</em>(6719), eadq2852. <a href="https://doi.org/10.1126/science.adq2852">https://doi.org/10.1126/science.adq2852</a>
</div>
<div id="ref-wangTaskSupportivePersonalized2024" class="csl-entry" role="listitem">
Wang, B., Liu, J., Karimnazarov, J., &amp; Thompson, N. (2024). Task <span>Supportive</span> and <span>Personalized Human-Large Language Model Interaction</span>: <span>A User Study</span>. <em>Proceedings of the 2024 <span>ACM SIGIR Conference</span> on <span>Human Information Interaction</span> and <span>Retrieval</span></em>, 370–375. <a href="https://doi.org/10.1145/3627508.3638344">https://doi.org/10.1145/3627508.3638344</a>
</div>
<div id="ref-wangTransitioningHumanCenteredAI2024" class="csl-entry" role="listitem">
Wang, D., Zheng, K., Li, C., &amp; Guo, J. (2024). Transitioning to <span>Human-Centered AI</span>: <span>A Systematic Review</span> of <span>Theories</span>, <span>Scenarios</span>, and <span>Hypotheses</span> in <span>Human-AI Interactions</span>. <em>Proceedings of the Association for Information Science and Technology</em>, <em>61</em>(1), 673–678. <a href="https://doi.org/10.1002/pra2.1078">https://doi.org/10.1002/pra2.1078</a>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/tegorman13\.github\.io\/ccl");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>