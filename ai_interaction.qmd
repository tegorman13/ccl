---
title: "Interactive AI Lit"
author:
- name: Thomas E. Gorman
  url: https://tegorman13.github.io/
  affiliations: 
  - name:  Communication and Cognition Lab, Purdue University, USA
    affiliation-url: https://web.ics.purdue.edu/~treimer/
date: today
toc: true
lightbox: true
format:
  html: default
  gfm: default
  docx:
    prefer-html: true
    output-file: "interactive_ai_lit_notes.docx"
    toc: false
---

## Task Supportive and Personalized Human-Large Language Model Interaction: A User Study. 

Wang, B., Liu, J., Karimnazarov, J., & Thompson, N. (2024). Task Supportive and Personalized Human-Large Language Model Interaction: A User Study. Proceedings of the 2024 ACM SIGIR Conference on Human Information Interaction and Retrieval, 370–375. https://doi.org/10.1145/3627508.3638344

<details class="relevant-callout">
<summary>Abstract</summary>
<div>
Large language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.
</div>
</details>

![Figure from](images/Wang_Liu1.png)




## Transitioning to Human-Centered AI: A Systematic Review of Theories, Scenarios, and Hypotheses in Human-AI Interactions.


Wang, D., Zheng, K., Li, C., & Guo, J. (2024). **Transitioning to Human-Centered AI: A Systematic Review of Theories, Scenarios, and Hypotheses in Human-AI Interactions.** Proceedings of the Association for Information Science and Technology, 61(1), 673–678. https://doi.org/10.1002/pra2.1078

<details class="relevant-callout">
<summary>Abstract</summary>
<div>
This study conducted a systematic review of human-AI interaction (HAI)over the past decade for the implemented theories and scenarios, and the tested hypotheses to discover the changes in the current transition to human-centered AI (HCAI). Moving from acceptance theories, Computers are social actors (CASA), anthropomorphism, and the integrative trust model are the most frequent theories. Augmentation scenarios of decision-making, teamwork, and human-AI collaborations are common in the latest HAI studies. Users' trust, acceptance, and intention to use an AI system are the main research targets in HAI studies. These trends show a clear transition toward HCAI. This paper also discusses opportunities tied to HAI studies based on the interconnections between the various theories, scenarios, and hypotheses.
</div>
</details>

::: {#fig-wang}

![](images/Wang1.png)

![](images/Wang2.png)

Figures from @wangTransitioningHumanCenteredAI2024

:::

